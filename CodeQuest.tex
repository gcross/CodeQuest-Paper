%@+leo-ver=4-thin
%@+node:gcross.20090405101642.3:@thin CodeQuest.tex
%@@language latex

%@<< Prelude >>
%@+node:gcross.20090405101642.4:<< Prelude >>
\documentclass[twocolumn,showpacs,preprintnumbers,amsmath,amssymb,nofootinbib,pra,floatfix]{revtex4}

\usepackage{mathrsfs}

%@-node:gcross.20090405101642.4:<< Prelude >>
%@nl

\begin{document}

%@+others
%@+node:gcross.20090405101642.5:Introduction
In the field of quantum computing, there is a grand battle between the forces of humankind, which seek to reliably store and manipulate quantum information, and the forces of nature, which generally seek to destroy it.  Although armies of experimentalists have made hereoic efforts to build systems that shield quantum information from harm, nature inevitably manages to get past these defences from time to time and strike a blow.  This might seem to paint a grim outlook for the possibility of building a quantum computer, but happily it turns out to be the case that one can generally repair damage to quantum information as long as one knows the exact form that the damage took, and furthermore that one can build a `trap' --- that is to say, a \emph{quantum code} --- that tricks nature into giving this information up.

Now, the nature of codes is that they decouple the space in which our computation lives from the space in which the physical information is stored;  that is to say, although we design our quantum circuit to operate on some space of qubits $\mathscr{C}$, each of these qubits does \emph{not} directly correspond to a physical qubit, but rather there is some isomorphism that relates the entire space $\mathscr{C}$ to the space of physical qubits, $\mathscr{P}$.  To distinguish between these two spaces, we shall call the space of qubits in whose terms the computation is expressed the \emph{computational space}, and the space of qubits which have physically been built the \emph{physical space}.

Of course, merely building an isomorphism between these two spaces is not enough to allow us to correct errors.  For one thing, we need to add extra qubits to the computational space that contain a record of the damage that we can read out;  thus, we shall say that the full computational space is $\mathscr{C}:=\mathscr{R}\times\mathscr{Q}$, where the qubits that live in $\mathscr{R}$ have the role of keeping a record of the errors that have been introduces, and the qubits that live in $\mathscr{Q}$ are the qubits in whose terms our quantum algorithm is expressed.  Since we are only performing measurements on $\mathscr{R}$, we can effectively ignore all operators except, say, the $Z$ measurement operator for each qubit;  this set of commuting operators allows us to completely measure the state of qubits in $\mathscr{R}$.  In order to build the `trap' element into our system, we need to ensure that whenever nature strikes at the physical space $\mathscr{P}$, it is isomorphic to a strike on the computational space that leaves a \emph{measureable} record in $\mathscr{R}$, which means in particular that it is isomorphic to an operator that must \emph{anti-commute} with the $Z$ operator (or whatever else we have chosen to be our basis of measurement) of one of the qubits in $\mathscr{R}$.  Note that although we speak of measuring the qubits in $\mathscr{R}$, they of course cannot be measured directly, but instead we take the measurement operator of interest in $\mathscr{R}$ and measure the \emph{isomorphic} operator in the physical space $\mathscr{P}$;  this isomorphic operator is referred to as a \emph{stabilizer}, and the full set of operators on $\mathscr{P}$ which are isomorphic to our chosen measurement operators on $\mathscr{R}$ are referred to as the \emph{stabilizers} of the code.

Up to this point, the formalism we have described is known as \emph{stabilizer codes} and its essential characteristic is the fact that with continuous measurement we force the each of the qubits in $\mathscr{R}$ to always have a definite value in some basis.  What if, however, we relaxed this restriction, and only continuously measured some of the qubits in $\mathscr{R}$?  At first there might not seem to be any advantage to doing this, since it essentially means creating a qubit in our system that is not being actively used;  however, this might be a price that one is willing to pay in order to make the system easier to engineer.  To see what is meant by this, consider that a problem that one can run when implementing stabilizer codes is that measuring stabilizers often requires implementing many-qubits measurements, which can be very difficult or even imposible to actually engineer.  However, this difficulty can often be circumvented by adding more qubits to the system and then utilizing measurements that are easier to engineer --- such as, say, 2-qubit measurement operators --- from whose measurement values one can distill the measurements of a specified subset of the qubits in $\mathscr{R}$.  Put another way, adding extra qubits to $\mathscr{R}$ that we do not use directly as part of the damage-repair process may make it easier for us to engineer measurements on the qubits in $\mathscr{R}$ that we \emph{do} use for this process.  When following this scheme, we have effectively split the qubits in $\mathscr{R}$ into two catagories:  \emph{stabilizer qubits} whose states we can completely measure and \emph{gauge qubits} whose states we cannot.  (The latter get their name from the fact that they provide a `gauge' degree of freedom, i.e. a degree of freedom that is irrelevent to us.)  Thus, we we have that $\mathscr{R}=\mathscr{S}\mathscr{G}$, where $\mathscr{S}$ is the space in which the stabilizers live, and $\mathscr{G}$ is the space in which the so-called gauge qubits.  A code with this property is called a \emph{subsystem code}, and the formalism of subsystem codes is more general than the formalism of stabilizer codes, as one can specialize from the former to the latter by simply not utilizing and gauge qubits.



Because of this, it might prove easier to implement a set of, say, 2-qubit measurement operators that do not fully commute, and to distill from these measurements the measured values of a specific subset of the qubits in $\mathscr{R}$;  in this case, `wasting' the rest of the qubits in $\mathscr{R}$ is a small price to pay in order to allow one to build the system at all.

Second, up to now it has taken no work from nature to damage our information, but constant work from us to repair it --- since if we let too much damage occur, then it will overwhelm our record and we will lose the ability to fix it.  This is a very unfair situation that demands to be redressed.


  One can do so by imposing an energetic barrier that nature needs to climb before striking at the information;  however, one needs to keep in mind that there is competing concern:  one does not want to create an energy landscape that favors some values of our stored quantum information over others, since then one one would actually make it easy for nature to damage our information by moving it downhill to an energetically favored value.  To accomplish this balence, one needs to engineer a Hamiltonian --- an operator $H$ on $\mathscr{H}$ --- that is isomorphic to some tensor product operator $R\otimes I_{\mathscr{Q}}$, where $R$ is an operator acting on $\mathscr{R}$ and $I_{\mathscr{Q}}$ is the identity on $\mathscr{Q}$.  This has both of the desired properties:  since we designed our isomorphism $\mathscr{H}\approx \mathscr{R}\times\mathscr{Q}$ so that sufficiently weak attacks on $\mathscr{H}$ are isomorphic to operations acting non-trivially on the qubits in $\mathscr{R}$, this means that there , while (necessarily high weight) actions on $\mathscr{H}$ that isomorphic to actions only on the $\mathscr{Q}$ components of vectors in $\mathscr{R}\times\mathscr{Q}$ do not affect the energy of the system.

the space in which our information is stored, $\mathscr{Q}$, is exactly isomorphic to the degenerate space of the ground states of $H$;  we want this because we do not want some values of our information qubits to be favored energetically over others, but we do want any errors --- which by construction are isomorphic to actions on $\mathscr{R}$ --- to kick the system into an excited state.




Within the stabilizer formalism, one can accomplish this by arranging the Hamiltonian to be the sum of the stabilizers -- i.e., to have the stabilizers themselves give the interactions of the system.  When this is done, one can obtain a system in which there is an energetic barrier to errors;  for an example of this, see  the \emph{toric code} by Kitaev.  However, the protection offered by these approaches is limited because it  provides only an energetic barrier to the first error, but not to additional errors; it can be shown that this is not just a specific property to these systems but a generic property of systems in two dimensions with commuting interactions.  Furthermore, many codes like the toric code also suffer from the problem of needing to engineer 4-qubit interactions.

Happily, we are not limited to commuting interactions in our Hamiltonian;  there is nothing stopping us from engineering a system with interactions that anti-commute.  When this is done, we leave behind the stabilizer code formalism to enter the more general formalism of \emph{subsystem codes}.  The reason for this name is as follows.  The protecting space $\mathscr{P}$ is no longer spanned only by stabilizers, but instead is split into a Cartesian product, $\mathscr{P}=\mathscr{S}\times\mathscr{G}$, of a space $\mathscr{S}$ spanned by stabilizers and a space $\mathscr{G}$ spanned by so-called \emph{gauge qubits}.  Thus, the full space in which quantum information can be stored in $\mathscr{H}=\mathscr{P}\times\mathscr{Q}\equiv\mathscr{S}\times\mathscr{G}\times\mathscr{Q}$ becomes $\mathscr{G}\times\mathscr{Q}$.  However, since we are interested in storing information in a manner that is energetically protected, we only choose to make use of the so-called \emph{logical qubits} spanning $\mathscr{Q}$, and ignore the qubits in $\mathscr{G}$;  thus we are storing our information in what can be considered a ``subsystem'' of the original system, and hence the name ``subsystem code''.  One particularly simple example of this is the two-dimensional compass model, where a set of local, 2-qubit, anti-commuting interactions in a square grid result in a subsystem code with energetic protection -- though like the toric code, the energetic protection only guards against the first error.

In fact, since all local interactions belong to the Pauli group and hence either commute or anti-commute with each other, this means that any such system that we build is guaranteed to give rise to some sort of subsystem code, and so the only question is whether this code is useful -- e.g., whether it has a degenerate ground state in which quantum information can be stored.  This perspective invites the following approach:  rather than starting with various encoding schemes and then trying to figure out how one might actually build a system which implements them, we can instead start with a class of systems which are feasible to build and ask if any of them have useful information storage properties;  this way, if any of them do, then they are guaranteed to not be far outside the range of experimentalists. 

In this paper, we perform computer-assisted searches for interesting subsystem codes in various classes of quantum systems that are in the range of being feasibly implementable.  We start by presenting an algorithm which computes the subsystem code implemented by a physical system composed of an arbitrary set of Pauli interactions.  Armed with a code implementing this algorithm, we explore the possibility of using systems with 2-local interactions in the pattern of the 11 uniform planar tilings, and offer evidence that only the square tiling gives rise to a useful subsystem code.  We then change tack from performing guided searches on particular lattice structures and instead perform a brute-force search through all of the possible 2-local interactions that can be placed on selected graphs of  size; the size of the graphs searched is small due to the cost of searching larger graphs, but this also has the benefit of limiting us to systems that can potentially be constructed in the near future.s



stacie.rae.woods@gmail.com
%@-node:gcross.20090405101642.5:Introduction
%@+node:gcross.20090423002455.2:Algorithm
\section{Algorithm}

Before describing the algorithm, we shall first define precisely the problem that it solves.

Assume that we have been given a list of operators $\tilde O :=\{O_1,\dots,O_n\}\in \mathcal{P}_n$ --- that is, a list of tensor products of $N$ Pauli operators which act on a Hilbert space of $N$ physical qubits, $\mathscr{H}^N$;  the source of these operators is unimportant as far as the algorithm is concerned, but in particular as described in the introduction they might come from the list of physical interactions that are summed in the Hamiltonian of a system, or alternatively they might be a list of measurements that are cheap to perform continuously on a system.  This list of operators, $\tilde O$, generates a subgroup of the full Pauli group on $N$ qubits, so that $\mathcal{O}\subseteq\mathcal{P_N}$.  In section \ref{cracking-the-code}, we will prove that given this setup, one can always find lists operators $\tilde S$ and $\tilde G$ -- respectively, ``stabilizers'' and ``gauge qubits'' -- such that the following properties hold:
\begin{itemize}
\item each of the operators in $\tilde S$ and $\tilde G$ is independent from the rest --- i.e., no operator can be written as a linear combination of operators in $\tilde S$ and $\tilde G$;
\item all of the operators in $\tilde S$ commute with all of the other operators in $\tilde S$ and also all of the operators in $\tilde G$;
\item the list $\tilde G$ can partitioned into a list of pairs of operators such that each operator in a pair commutes with all of the operators in $\tilde S$ and $\tilde G$ \emph{except} for the other operator in its pair, with which it \emph{anti-commutes};
\item the subgroup generated by $\tilde S \cup \tilde G$ is exactly the subgroup $\mathcal{O}$ generated by $\tilde O$.
\end{itemize}
The proof that we give in \ref{cracking-the-code} will be constructive, and hence will also serve to explain our algorithm for computing $\tilde S$ and $\tilde G$, which is the first step in computing the subsystem code.

Now that we know the stabilizers and gauge qubits, in order to complete the subsystem code it remains to compute the logical qubits. Formally, this is a list of operators $\tilde L$ which satisfy the following properties
\begin{itemize}
\item the full list of operators given in $\tilde S$, $\tilde G$, and $\tilde L$ are all independent;
\item the list $\tilde L$ can be partitioned into a list of pairs of operators such that each operator in a pair commutes with all of the operators in $\tilde S$, $\tilde G$, and $\tilde L$ \emph{except} for the other operator in its pair, with which it \emph{anti-commutes};
\item **** \footnote{Note that although $\mathscr{H}^N=\mathscr{S}\times\mathscr{G}\times\mathscr{L}$, this does not mean in general that $\mathcal{P}^N=\left<\tilde S,\tilde G,\tilde L\right>$, i.e. that the subgroup generated by the stabilizers, gauge qubits, and logical qubits is equal to the full Pauli group.  This can quickly be seen by the fact that $\mathcal{P}^N$ requires $2N$ independent generators (excluding multiplicative factors of $\pm 1$ and $\pm i$), whereas $|\tilde S|+|\tilde G|+|\tilde L|=k+2l+2(N-k-l)=2N-k\le 2N$.  This can also be seen informally by considering that every operator in $\mathcal{P}^N$ must have an operator that anti-commutes with it, since otherwise we would have, informally, a qubit with a degree of freedom that we could not touch; thus, since as long as $|\tilde S|>0$, there exists an operator with which no operator anti-commutes, we must have in this case that $\left<\tilde S,\tilde G,\tilde L\right>\ne \mathcal{P}^N$.}.
\end{itemize}
In section \ref{finishing-the-job} we shall prove that a list of operators $\tilde L$ can be constructed with these properties, which is the final step in computing the subsystem code.

However, at this point the problem is not yet completely solved because at there is another important piece of information that we need, which is:  how many errors does it take for the environment to destroy the information in our code so thoroughly that we don't even notice that it is gone?  More formally, we want to know the \emph{minimum weight error}, the operator in $\mathcal{P}^N$ which contains the fewest number of non-identity Pauli operators in its tensor product that both acts trivially on the space $\mathscr{S}\times\mathscr{G}$ and non-trivially on the space $\mathscr{L}$, since the application of such an operator to our system is the smallest interaction that can damage the stored logical information without leaving any sign that this was done that could be measured in the protecting space $\mathscr{P}:=\mathscr{S}\times\mathscr{G}$.

However, if there is more than one logical qubit than learning the minimum weight error is not enough, because it might be possible for 
%@nonl
%@+node:gcross.20090423002455.3:Cracking the code
\subsection{Cracking the code}

\label{cracking-the-code}
%@-node:gcross.20090423002455.3:Cracking the code
%@+node:gcross.20090427140200.2:Finishing the job
\subsection{Finishing the job}
\label{finishing-the-job}
%@-node:gcross.20090427140200.2:Finishing the job
%@-node:gcross.20090423002455.2:Algorithm
%@-others

\end{document}
%@nonl
%@-node:gcross.20090405101642.3:@thin CodeQuest.tex
%@-leo
