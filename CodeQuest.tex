%@+leo-ver=4-thin
%@+node:gcross.20090405101642.3:@thin CodeQuest.tex
%@@language latex

%@<< Prelude >>
%@+node:gcross.20090405101642.4:<< Prelude >>
\documentclass[twocolumn,showpacs,preprintnumbers,amsmath,amssymb,nofootinbib,pra,floatfix]{revtex4}

\usepackage{mathrsfs}

%@-node:gcross.20090405101642.4:<< Prelude >>
%@nl

\begin{document}

%@+others
%@+node:gcross.20090405101642.5:Introduction
In the field of quantum computing, there is a grand battle between the forces of humankind, which seek to reliably store and manipulate quantum information, and the forces of nature, which generally seek to destroy it.  Although armies of experimentalists have made hereoic efforts to build systems that shield quantum information from harm, nature inevitably manages to get past these defences from time to time and strike a blow.  Happily, most of the damage that is caused can be reversed as long as we know the exact form that it took, and hence a general strategy that is employed by the forces of humankind is to create a trap that tricks nature into revealing this information to us.

A key ingrediant of such traps is a mechanism for keeping the record of the damages that have transpired;  the raw material for storing this record is the same that is used to store our precious quantum information --- namely some form of physically constructed qubits.  However, to merely add extra physical qubits that create space for such a record would be to create a poor trap, for there would be nothing stopping nature from simply walking past these qubits and striking at the qubits that store our information.  Instead, we need to mix the two kinds of qubits together in order to make it hard for nature to avoid the trap.

We now state this same idea in formal language.  There are two kinds of information that we want to store in our system:  the precious $j$ qubits of quantum information that we are trying to protect, which naturally live in some Hilbert space $\mathscr{Q}\approx\mathbb{C}^{2j}$ (that is, $\mathscr{Q}$ is isomorphic to $\mathbb{C}^j$), and the $k$ qubits that we are using to keep a record of the damage that nature has done, which naturally live in some Hilbert space $\mathscr{R}\approx\mathbb{C}^{2k}.$  All of this information will be stored within a phyical system of $n:=j+k$ physical qubits that live in a Hilbert space $\mathscr{H}\approx\mathbb{C}^{2n}$.  However, we shall not have that $\mathscr{H}=\mathscr{Q}\times\mathscr{R}$ --- which would mean that each qubit in $\mathscr{H}$ corresponded directly to a qubit in either $\mathscr{Q}$ or $\mathscr{R}$ --- but merely that $\mathscr{H}\approx^T\mathscr{Q}\times\mathscr{R}$, so that the physical space and the conceptual space in which our information lives are \emph{isomorphic} (via some linear transformation $T:\mathscr{H}\to\mathscr{Q}\times\mathscr{R} $) but not necessarily equal.  A key to building an effective trap is to engineer the isomorphism $T$ so that sufficiently weak damage to $\mathscr{H}$ always results in a change in $\mathscr{R}$ --- stated formally, we want all operators acting on $\mathscr{H}$ that act nontrivially on sufficiently few qubits to always be isomorphic (via $T$) to an operator acting on $\mathscr{Q}\times\mathscr{R}$ that acts nontrivially on $\mathscr{R}$.  In this way we can be guaranteed that nature will always fall for our trap (assuming that its blows penetrate with sufficient weakness and infrequency) so in the very moment of its act of destruction it simultaneously gives us the key we need to reverse its damage.



Now when we want to actually do something to our system, we are usually interested in operators that conceptually act on $\mathscr{Q}\times\mathscr{R}$, since this is the space in which our information is easily accessible.  However, alhto


  However, it is unlikely that we are going to be able to actually engineer an apparatus which performs the isomorphism $T:\mathscr{H}\to\mathscr{Q}\times\mathscr{R}$ on our system, and even if we could it would likely be undeisrable since it would remove the protection from the system.  

Thus, it makes sense to create a system for doing this.  A popular tactic that has been employed goes by the name of ``stabilizer codes'', and involves creating a set of commuting operators inside of $\mathscr{H}$ that allow us to pick a particular 

  Happily, we have at our advantage the fact that when we completely measure all of the degrees of freedom inside $\mathscr{M}$, we force nature to pick a particular coordinate within this

To do this, it is necessary to map the coordinates in this space to 

;  this tactic goes by the name of  \emph{stabilizer codes}.  These operate by 

These organize the information in the subspace $\mathscr{P}$ by employing a set of \emph{stabilizers}, which are operators acting on $\mathscr{P}$ that all commute and hence can be simultaneously diagonalized.

 that only act on the subspace .  These operators are designed so that errors acting on a single physical qubit (and possibly more) act within the subspace $\mathscr{P}$ but not within the subspace $\mathscr{Q}$, so that they effectively blow our sheltered subspace $\mathscr{Q}$ around $\mathscr{H}$ without touching the information inside;  we can tell to where the shelter has been moved by continuously monitoring the stabilizers (as they commute with everything and hence can be simultaneously diagonalized), and if one has designed the system with cleverness, one can learn about enough the error caused by nature to correct it, moving the subspace $\mathscr{Q}$ back to its original location within $\mathscr{H}$.  In short, the stabilizer formalism does  just what we need to protect our quantum information.

However, merely having a theoretical strategy for protecting quantum information is not enough;  the strategy also has to lead to a system that one can actually \emph{build}, and here stabilizer codes can often fall short.  For example, the 5-qubit Shor code, while being an impressive example of protecting quantum information using only a small number of physical qubits, requires implementing 4-qubit operations, which can be troublesome in practice.

Furthermore, when one starts thinking in terms of actually building a physical system, one realizes that one has another resource on their side:  one can actually try enlisting nature's help in preventing and possibly correcting the errors that it causes, reducing the cost burden that we need to bear to keep the information safe.  The general idea behind this is that we build a physical system whose interactions span the subspace $\mathscr{P}$, thus making the (degenerate) ground states of the system span the subspace $\mathscr{Q}$;  if set up correctly, errors will force the system into an excited state, and hence will be guarded against by an energetic barrier.

Within the stabilizer formalism, one can accomplish this by arranging the Hamiltonian to be the sum of the stabilizers -- i.e., to have the stabilizers themselves give the interactions of the system.  When this is done, one can obtain a system in which there is an energetic barrier to errors;  for an example of this, see  the \emph{toric code} by Kitaev.  However, the protection offered by these approaches is limited because it  provides only an energetic barrier to the first error, but not to additional errors; it can be shown that this is not just a specific property to these systems but a generic property of systems in two dimensions with commuting interactions.  Furthermore, many codes like the toric code also suffer from the problem of needing to engineer 4-qubit interactions.

Happily, we are not limited to commuting interactions in our Hamiltonian;  there is nothing stopping us from engineering a system with interactions that anti-commute.  When this is done, we leave behind the stabilizer code formalism to enter the more general formalism of \emph{subsystem codes}.  The reason for this name is as follows.  The protecting space $\mathscr{P}$ is no longer spanned only by stabilizers, but instead is split into a Cartesian product, $\mathscr{P}=\mathscr{S}\times\mathscr{G}$, of a space $\mathscr{S}$ spanned by stabilizers and a space $\mathscr{G}$ spanned by so-called \emph{gauge qubits}.  Thus, the full space in which quantum information can be stored in $\mathscr{H}=\mathscr{P}\times\mathscr{Q}\equiv\mathscr{S}\times\mathscr{G}\times\mathscr{Q}$ becomes $\mathscr{G}\times\mathscr{Q}$.  However, since we are interested in storing information in a manner that is energetically protected, we only choose to make use of the so-called \emph{logical qubits} spanning $\mathscr{Q}$, and ignore the qubits in $\mathscr{G}$;  thus we are storing our information in what can be considered a ``subsystem'' of the original system, and hence the name ``subsystem code''.  One particularly simple example of this is the two-dimensional compass model, where a set of local, 2-qubit, anti-commuting interactions in a square grid result in a subsystem code with energetic protection -- though like the toric code, the energetic protection only guards against the first error.

In fact, since all local interactions belong to the Pauli group and hence either commute or anti-commute with each other, this means that any such system that we build is guaranteed to give rise to some sort of subsystem code, and so the only question is whether this code is useful -- e.g., whether it has a degenerate ground state in which quantum information can be stored.  This perspective invites the following approach:  rather than starting with various encoding schemes and then trying to figure out how one might actually build a system which implements them, we can instead start with a class of systems which are feasible to build and ask if any of them have useful information storage properties;  this way, if any of them do, then they are guaranteed to not be far outside the range of experimentalists. 

In this paper, we perform computer-assisted searches for interesting subsystem codes in various classes of quantum systems that are in the range of being feasibly implementable.  We start by presenting an algorithm which computes the subsystem code implemented by a physical system composed of an arbitrary set of Pauli interactions.  Armed with a code implementing this algorithm, we explore the possibility of using systems with 2-local interactions in the pattern of the 11 uniform planar tilings, and offer evidence that only the square tiling gives rise to a useful subsystem code.  We then change tack from performing guided searches on particular lattice structures and instead perform a brute-force search through all of the possible 2-local interactions that can be placed on selected graphs of  size; the size of the graphs searched is small due to the cost of searching larger graphs, but this also has the benefit of limiting us to systems that can potentially be constructed in the near future.
%@nonl
%@-node:gcross.20090405101642.5:Introduction
%@+node:gcross.20090423002455.2:Algorithm
\section{Algorithm}

Before describing the algorithm, we shall first define precisely the problem that it solves.

Assume that we have been given a list of operators $\tilde O :=\{O_1,\dots,O_n\}\in \mathcal{P}_n$ --- that is, a list of tensor products of $N$ Pauli operators which act on a Hilbert space of $N$ physical qubits, $\mathscr{H}^N$;  the source of these operators is unimportant as far as the algorithm is concerned, but in particular as described in the introduction they might come from the list of physical interactions that are summed in the Hamiltonian of a system, or alternatively they might be a list of measurements that are cheap to perform continuously on a system.  This list of operators, $\tilde O$, generates a subgroup of the full Pauli group on $N$ qubits, so that $\mathcal{O}\subseteq\mathcal{P_N}$.  In section \ref{cracking-the-code}, we will prove that given this setup, one can always find lists operators $\tilde S$ and $\tilde G$ -- respectively, ``stabilizers'' and ``gauge qubits'' -- such that the following properties hold:
\begin{itemize}
\item each of the operators in $\tilde S$ and $\tilde G$ is independent from the rest --- i.e., no operator can be written as a linear combination of operators in $\tilde S$ and $\tilde G$;
\item all of the operators in $\tilde S$ commute with all of the other operators in $\tilde S$ and also all of the operators in $\tilde G$;
\item the list $\tilde G$ can partitioned into a list of pairs of operators such that each operator in a pair commutes with all of the operators in $\tilde S$ and $\tilde G$ \emph{except} for the other operator in its pair, with which it \emph{anti-commutes};
\item the subgroup generated by $\tilde S \cup \tilde G$ is exactly the subgroup $\mathcal{O}$ generated by $\tilde O$.
\end{itemize}
The proof that we give in \ref{cracking-the-code} will be constructive, and hence will also serve to explain our algorithm for computing $\tilde S$ and $\tilde G$, which is the first step in computing the subsystem code.

Now that we know the stabilizers and gauge qubits, in order to complete the subsystem code it remains to compute the logical qubits. Formally, this is a list of operators $\tilde L$ which satisfy the following properties
\begin{itemize}
\item the full list of operators given in $\tilde S$, $\tilde G$, and $\tilde L$ are all independent;
\item the list $\tilde L$ can be partitioned into a list of pairs of operators such that each operator in a pair commutes with all of the operators in $\tilde S$, $\tilde G$, and $\tilde L$ \emph{except} for the other operator in its pair, with which it \emph{anti-commutes};
\item **** \footnote{Note that although $\mathscr{H}^N=\mathscr{S}\times\mathscr{G}\times\mathscr{L}$, this does not mean in general that $\mathcal{P}^N=\left<\tilde S,\tilde G,\tilde L\right>$, i.e. that the subgroup generated by the stabilizers, gauge qubits, and logical qubits is equal to the full Pauli group.  This can quickly be seen by the fact that $\mathcal{P}^N$ requires $2N$ independent generators (excluding multiplicative factors of $\pm 1$ and $\pm i$), whereas $|\tilde S|+|\tilde G|+|\tilde L|=k+2l+2(N-k-l)=2N-k\le 2N$.  This can also be seen informally by considering that every operator in $\mathcal{P}^N$ must have an operator that anti-commutes with it, since otherwise we would have, informally, a qubit with a degree of freedom that we could not touch; thus, since as long as $|\tilde S|>0$, there exists an operator with which no operator anti-commutes, we must have in this case that $\left<\tilde S,\tilde G,\tilde L\right>\ne \mathcal{P}^N$.}.
\end{itemize}
In section \ref{finishing-the-job} we shall prove that a list of operators $\tilde L$ can be constructed with these properties, which is the final step in computing the subsystem code.

However, at this point the problem is not yet completely solved because at there is another important piece of information that we need, which is:  how many errors does it take for the environment to destroy the information in our code so thoroughly that we don't even notice that it is gone?  More formally, we want to know the \emph{minimum weight error}, the operator in $\mathcal{P}^N$ which contains the fewest number of non-identity Pauli operators in its tensor product that both acts trivially on the space $\mathscr{S}\times\mathscr{G}$ and non-trivially on the space $\mathscr{L}$, since the application of such an operator to our system is the smallest interaction that can damage the stored logical information without leaving any sign that this was done that could be measured in the protecting space $\mathscr{P}:=\mathscr{S}\times\mathscr{G}$.

However, if there is more than one logical qubit than learning the minimum weight error is not enough, because it might be possible for 
%@nonl
%@+node:gcross.20090423002455.3:Cracking the code
\subsection{Cracking the code}

\label{cracking-the-code}
%@-node:gcross.20090423002455.3:Cracking the code
%@+node:gcross.20090427140200.2:Finishing the job
\subsection{Finishing the job}
\label{finishing-the-job}
%@-node:gcross.20090427140200.2:Finishing the job
%@-node:gcross.20090423002455.2:Algorithm
%@-others

\end{document}
%@nonl
%@-node:gcross.20090405101642.3:@thin CodeQuest.tex
%@-leo
